# Docker Environment Configuration for Local AI Development

# ==============================================
# LOCAL AI DEVELOPMENT MODE
# ==============================================

# Disable AWS Bedrock (use mock instead)
BEDROCK_USE_MOCK=true
BEDROCK_FALLBACK_TO_MOCK=true
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""

# Enable Ollama for local AI
OLLAMA_AVAILABLE=true
OLLAMA_BASE_URL=http://ollama:11434

# Enable Claude if you have API key (optional)
CLAUDE_AVAILABLE=false
# ANTHROPIC_API_KEY=your_claude_key_here

# Database
DATABASE_URL=sqlite:///predictions.db

# Logging
LOG_LEVEL=INFO

# API Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true

# ==============================================
# PRODUCTION SETTINGS (uncomment when ready)
# ==============================================

# Real AWS Bedrock (when credentials available)
# BEDROCK_USE_MOCK=false
# AWS_ACCESS_KEY_ID=your_aws_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret
# AWS_DEFAULT_REGION=us-east-1

# Claude API (when key available)
# CLAUDE_AVAILABLE=true
# ANTHROPIC_API_KEY=your_claude_key
